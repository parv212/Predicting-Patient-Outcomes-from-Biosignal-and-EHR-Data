{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edb296b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# modelling libs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, Dropout, Bidirectional, Conv1D, MaxPooling1D, Input, concatenate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "073a40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped patient IDs:  [1242, 4452]\n",
      "bioData shape:  (6386, 5000, 3)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# load biosignal data\n",
    "# ----------------------\n",
    "\n",
    "# biosignals\n",
    "with open('biosignals.pkl','rb') as f:\n",
    "    bioData = pickle.load(f)\n",
    "\n",
    "# dropped indexes\n",
    "with open('droppedIndices.pkl','rb') as f:\n",
    "    dropIdx = pickle.load(f)\n",
    "    print('dropped patient IDs: ', dropIdx)\n",
    "    \n",
    "# reduce length of biosignals for demo purposes\n",
    "bioData = bioData[:,0:5000,:]\n",
    "print('bioData shape: ', bioData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cb21613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ehrData shape:  (6386, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ta1031742\\AppData\\Local\\Temp\\ipykernel_27524\\3144206413.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ehrData['sex'] = ehrData['sex'].replace(to_replace={'M': 0, 'F': 1})\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# load ehr data \n",
    "# --------------------\n",
    "\n",
    "# load all ehr data\n",
    "dataFile = r'C:\\Users\\ta1031742\\OneDrive - Bose Corporation\\Documents\\Admin\\Northeastern\\DS5500-Capstone\\Data\\vitaldb\\vitaldb-a-high-fidelity-multi-parameter-vital-signs-database-in-surgical-patients-1.0.0\\clinical_data.csv'\n",
    "data = pd.read_csv(dataFile)\n",
    "\n",
    "# downselect features for demo purposes\n",
    "ehrData = data[['sex', 'height', 'weight', 'bmi', 'asa', 'icu_days']]\n",
    "\n",
    "# replace gender values\n",
    "ehrData['sex'] = ehrData['sex'].replace(to_replace={'M': 0, 'F': 1})\n",
    "\n",
    "# drop bad indexes from biosisgnals data\n",
    "ehrData = ehrData.drop(index=dropIdx).reset_index(drop=True)\n",
    "\n",
    "# fill missing values\n",
    "ehrData = ehrData.fillna(value=-999)\n",
    "\n",
    "print('ehrData shape: ', ehrData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52a160c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testBio shape:  (1277, 5000, 3)\n",
      "trainBio shape:  (5108, 5000, 3)\n",
      "\n",
      "yTest shape:  (1277,)\n",
      "yTrain shape:  (5108,)\n",
      "testEhr shape:  (1277, 5)\n",
      "trainEhr shape:  (5108, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# create train, test sets\n",
    "# ---------------------------\n",
    "\n",
    "# randomly specify train, test indices\n",
    "random.seed(42)\n",
    "allIdx = np.linspace(0,6385,6385, dtype=int) # create list of all patient id's\n",
    "testIdx = random.sample(range(1, len(df)), int(np.floor(len(df)*0.2))) # randomly generate test indices\n",
    "trainIdx = list(set(allIdx) - set(testIdx)) # get train indices\n",
    "\n",
    "# separate biosignal data into train, test sets\n",
    "testBio = bioData[testIdx, :, :]\n",
    "trainBio = bioData[trainIdx, :, :]\n",
    "print('testBio shape: ', testBio.shape)\n",
    "print('trainBio shape: ', trainBio.shape); print()\n",
    "\n",
    "# separate y (icu_days) from data\n",
    "y = ehrData['icu_days']\n",
    "ehrData = ehrData.drop(columns='icu_days')\n",
    "\n",
    "# separate y into train, test sets\n",
    "yTest = y[testIdx]\n",
    "yTrain = y[trainIdx]\n",
    "print('yTest shape: ', yTest.shape)\n",
    "print('yTrain shape: ', yTrain.shape)\n",
    "\n",
    "# separate ehr data into train, test sets\n",
    "ehrData = ehrData.to_numpy()\n",
    "testEhr = ehrData[testIdx, :]\n",
    "trainEhr = ehrData[trainIdx, :]\n",
    "print('testEhr shape: ', testEhr.shape)\n",
    "print('trainEhr shape: ', trainEhr.shape); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4b83c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 5000, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 20)          1120        ['input_5[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 25)           0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           832         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# build model\n",
    "# ---------------------\n",
    "\n",
    "maxLen = 5000 # length of biosignal data (change to 28215 if you keep the original length of the biosignals)\n",
    "\n",
    "seq_inp = Input(shape=(maxLen,3)) # input layer for sequential data (biosignal data)\n",
    "nonseq_inp = Input(shape=(trainEhr.shape[1],)) # input layer for non-sequential data (ehr data)\n",
    "x = Bidirectional(LSTM(10, input_shape=(trainBio.shape[1], trainBio.shape[2])))(seq_inp) # sequential data goes through lstm\n",
    "x = concatenate([x, nonseq_inp]) # then concatenate with non-seq data\n",
    "x = Dense(32, activation=\"relu\")(x) # dense layer\n",
    "out = Dense(1, activation=\"sigmoid\")(x) # output layer\n",
    "model = Model(inputs=[seq_inp, nonseq_inp], outputs=out)\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e12bf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ta1031742\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 83s 5s/step - loss: 2.0979 - accuracy: 0.3177 - val_loss: 1.1595 - val_accuracy: 0.7720\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 120s 8s/step - loss: 0.7780 - accuracy: 0.6755 - val_loss: 0.2071 - val_accuracy: 0.2387\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 97s 6s/step - loss: 0.5977 - accuracy: 0.4907 - val_loss: 0.2654 - val_accuracy: 0.6468\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 100s 6s/step - loss: 0.4896 - accuracy: 0.5174 - val_loss: 0.1970 - val_accuracy: 0.6174\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 102s 6s/step - loss: 0.4778 - accuracy: 0.6016 - val_loss: 0.0048 - val_accuracy: 0.4022\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 96s 6s/step - loss: 0.3649 - accuracy: 0.6219 - val_loss: -0.0361 - val_accuracy: 0.6096\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.3334 - accuracy: 0.5330 - val_loss: 0.0247 - val_accuracy: 0.6957\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 94s 6s/step - loss: 0.2782 - accuracy: 0.5857 - val_loss: -0.2662 - val_accuracy: 0.5303\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 91s 6s/step - loss: 0.2403 - accuracy: 0.6397 - val_loss: -0.3429 - val_accuracy: 0.4775\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 92s 6s/step - loss: 0.2429 - accuracy: 0.5438 - val_loss: -0.0203 - val_accuracy: 0.7260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215d6efbe20>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------\n",
    "# train\n",
    "# -------\n",
    "model.fit([trainBio, trainEhr], yTrain, epochs=10, batch_size=256, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
